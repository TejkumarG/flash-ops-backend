{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flash-Ops NL2SQL Visualization\n",
    "\n",
    "This notebook provides visualization tools for:\n",
    "1. FAISS vector embeddings (table similarity)\n",
    "2. Query pipeline performance\n",
    "3. Table clustering results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style('whitegrid')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load FAISS Index and Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from app.services import get_vector_store\n",
    "\n",
    "# Load vector store\n",
    "vector_store = get_vector_store()\n",
    "\n",
    "print(f\"Index loaded: {vector_store.loaded}\")\n",
    "print(f\"Total tables: {len(vector_store.metadata) if vector_store.metadata else 0}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualize Table Embeddings (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "if vector_store.loaded:\n",
    "    # Get embeddings from FAISS index\n",
    "    n_vectors = vector_store.index.ntotal\n",
    "    embeddings = np.zeros((n_vectors, vector_store.index.d))\n",
    "    \n",
    "    for i in range(n_vectors):\n",
    "        embeddings[i] = vector_store.index.reconstruct(i)\n",
    "    \n",
    "    # Apply PCA\n",
    "    pca = PCA(n_components=2)\n",
    "    embeddings_2d = pca.fit_transform(embeddings)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df_viz = pd.DataFrame({\n",
    "        'x': embeddings_2d[:, 0],\n",
    "        'y': embeddings_2d[:, 1],\n",
    "        'table': [m['table_name'] for m in vector_store.metadata],\n",
    "        'category': [m.get('category', 'unknown') for m in vector_store.metadata]\n",
    "    })\n",
    "    \n",
    "    # Plot\n",
    "    fig = px.scatter(\n",
    "        df_viz,\n",
    "        x='x',\n",
    "        y='y',\n",
    "        color='category',\n",
    "        hover_data=['table'],\n",
    "        title='Table Embeddings Visualization (PCA)',\n",
    "        width=1000,\n",
    "        height=700\n",
    "    )\n",
    "    fig.show()\n",
    "else:\n",
    "    print(\"Vector store not loaded. Generate embeddings first.\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Table Similarity Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "if vector_store.loaded:\n",
    "    # Calculate similarity for first 20 tables\n",
    "    n_tables = min(20, len(vector_store.metadata))\n",
    "    sample_embeddings = embeddings[:n_tables]\n",
    "    \n",
    "    similarity_matrix = cosine_similarity(sample_embeddings)\n",
    "    \n",
    "    # Plot heatmap\n",
    "    table_names = [m['table_name'][:20] for m in vector_store.metadata[:n_tables]]\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(\n",
    "        similarity_matrix,\n",
    "        xticklabels=table_names,\n",
    "        yticklabels=table_names,\n",
    "        cmap='viridis',\n",
    "        annot=False,\n",
    "        cbar_kws={'label': 'Cosine Similarity'}\n",
    "    )\n",
    "    plt.title('Table Similarity Heatmap (Top 20 Tables)')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test Query and Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import requests\n",
    "\n",
    "# Test query\n",
    "test_query = \"show all active employees\"\n",
    "\n",
    "response = requests.post(\n",
    "    \"http://localhost:8000/api/v1/query/\",\n",
    "    json={\"query\": test_query}\n",
    ")\n",
    "\n",
    "if response.status_code == 200:\n",
    "    result = response.json()\n",
    "    \n",
    "    print(f\"Status: {result['status']}\")\n",
    "    print(f\"Tables used: {result['tables_used']}\")\n",
    "    print(f\"Tier: {result['tier']}\")\n",
    "    print(f\"Confidence: {result['confidence']:.3f}\")\n",
    "    print(f\"Execution time: {result['execution_time_ms']}ms\")\n",
    "    print(f\"\\nGenerated SQL:\\n{result['sql_generated']}\")\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}\")\n",
    "    print(response.text)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Clustering Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from app.agents import create_table_clustering\n",
    "\n",
    "if vector_store.loaded and len(vector_store.metadata) > 5:\n",
    "    # Sample tables for clustering demo\n",
    "    sample_tables = vector_store.metadata[:30]\n",
    "    \n",
    "    # Add scores (mock)\n",
    "    for i, table in enumerate(sample_tables):\n",
    "        table['score'] = 0.9 - (i * 0.02)\n",
    "    \n",
    "    # Cluster\n",
    "    clustering = create_table_clustering()\n",
    "    clusters = clustering.cluster_tables(sample_tables)\n",
    "    \n",
    "    print(f\"Created {len(clusters)} clusters:\")\n",
    "    for i, cluster in enumerate(clusters):\n",
    "        print(f\"\\nCluster {i+1} ({len(cluster)} tables):\")\n",
    "        for table in cluster[:5]:  # Show first 5\n",
    "            print(f\"  - {table['table_name']} (score: {table.get('score', 0):.2f})\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Test multiple queries and measure performance\n",
    "test_queries = [\n",
    "    \"show all employees\",\n",
    "    \"count active users\",\n",
    "    \"sales by department\",\n",
    "    \"employee with highest salary\"\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for query in test_queries:\n",
    "    response = requests.post(\n",
    "        \"http://localhost:8000/api/v1/query/\",\n",
    "        json={\"query\": query}\n",
    "    )\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        results.append({\n",
    "            'query': query,\n",
    "            'status': data['status'],\n",
    "            'tier': data['tier'],\n",
    "            'execution_time_ms': data['execution_time_ms'],\n",
    "            'confidence': data['confidence']\n",
    "        })\n",
    "\n",
    "# Visualize\n",
    "df_perf = pd.DataFrame(results)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Execution time\n",
    "axes[0].bar(range(len(df_perf)), df_perf['execution_time_ms'])\n",
    "axes[0].set_xlabel('Query')\n",
    "axes[0].set_ylabel('Execution Time (ms)')\n",
    "axes[0].set_title('Query Execution Time')\n",
    "axes[0].set_xticks(range(len(df_perf)))\n",
    "axes[0].set_xticklabels(range(1, len(df_perf)+1))\n",
    "\n",
    "# Confidence\n",
    "axes[1].bar(range(len(df_perf)), df_perf['confidence'], color='orange')\n",
    "axes[1].set_xlabel('Query')\n",
    "axes[1].set_ylabel('Confidence Score')\n",
    "axes[1].set_title('Query Confidence Scores')\n",
    "axes[1].set_xticks(range(len(df_perf)))\n",
    "axes[1].set_xticklabels(range(1, len(df_perf)+1))\n",
    "axes[1].set_ylim([0, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPerformance Summary:\")\n",
    "print(df_perf.to_string(index=False))"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
